{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b028c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0111de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6178ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1126bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6563c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbec975",
   "metadata": {},
   "source": [
    "# Task description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdd17",
   "metadata": {},
   "source": [
    "- train NER model to extract geo, gpe, tim and nat entities\n",
    "- experiment with different language model sizes\n",
    "- experiment with DROPOUT and epochs to get the best test set results\n",
    "- analize learning curves and performance per entity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a96ca",
   "metadata": {},
   "source": [
    "News entities\n",
    "- geo = Geographical Entity\n",
    "- gpe = Geopolitical Entity\n",
    "- tim = Time indicator\n",
    "- nat = Natural Phenomenon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7502420",
   "metadata": {},
   "source": [
    "# Prepare NER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17bbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/GMB_data_spacy_geo.pickle', 'rb') as f:\n",
    "     spacy_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "290c9f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35177"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a87e187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [(41, 47, 'gpe')]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_data[33000][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44801496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lebanon 's top Shi'ite cleric is opposing British Prime Minister Tony Blair 's expected visit to Beirut Monday .\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_data[35000][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64589ef5",
   "metadata": {},
   "source": [
    "## Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide spacy into train and test sets\n",
    "spacy_data_train, spacy_data_test = train_test_split(spacy_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c274e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_data_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16012f23",
   "metadata": {},
   "source": [
    "## NER model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4659a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model - experiment with sm, md, lg\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "ner = nlp.create_pipe('ner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_examples_to_batches(examples, batch_size):\n",
    "    batches=[]\n",
    "    for i in range(0, math.ceil(len(examples)/batch_size)):\n",
    "        start=i*batch_size\n",
    "        end = start+batch_size\n",
    "        batches.append(examples[start:end])\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d746888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_examples(data):\n",
    "    examples = []\n",
    "    for i in range(0, len(data)):\n",
    "        raw_text, entity_offsets = data[i]\n",
    "\n",
    "        try:\n",
    "\n",
    "            doc= nlp.make_doc(raw_text.lower())\n",
    "            example_test = Example.from_dict(doc, entity_offsets)\n",
    "            examples.append(example_test)\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare examples\n",
    "examples_train = prepare_examples(spacy_data_train)\n",
    "examples_test = prepare_examples(spacy_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb83a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2058e",
   "metadata": {},
   "source": [
    "### Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "940ccbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in spacy_data:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "303b401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('geo', 'gpe', 'nat', 'tim')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1118c98",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT=0.1\n",
    "epochs = 10\n",
    "\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd740f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ner(nlp, examples_train, examples_test, epochs, batch_size, dropout):\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.create_optimizer()\n",
    "        scores = []\n",
    "\n",
    "        for i in range(0, epochs):\n",
    "            random.shuffle(examples_train)\n",
    "\n",
    "            batches = split_examples_to_batches(examples_train, batch_size)\n",
    "            for batch in  tqdm(batches):\n",
    "                try:\n",
    "                        nlp.update(batch, sgd=optimizer, drop =DROPOUT)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "            train_score = nlp.evaluate(examples_train)\n",
    "            val_score = nlp.evaluate(examples_test)\n",
    "            total_f = val_score['ents_f']\n",
    "\n",
    "            scores.append({\"iter\":i, \"val_score\":val_score, \"train_score\":train_score})\n",
    "\n",
    "            print(f\"Iter:{i}, f_score:{round(total_f,2)}\")\n",
    "\n",
    "    return nlp, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp, scores = train_ner(nlp, examples_train, examples_test, epochs, batch_size, DROPOUT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4ad8c11",
   "metadata": {},
   "source": [
    "# Model save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9fb1db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spacy_model(nlp, model_path):\n",
    "    nlp.to_disk(f'{model_path}')\n",
    "    print(f\"Saved model to {model_path}\")\n",
    "    bytes_data = nlp.to_bytes()\n",
    "\n",
    "    f = open(f'{model_path}/bytes_data.bin', 'wb')\n",
    "    f.write(bytes_data)\n",
    "    f.close()\n",
    "    print(f\"Saved bytes_data to f'{model_path}/bytes_data.bin'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "35b3d419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to that_one_model_which_is_diff\n",
      "Saved bytes_data to f'that_one_model_which_is_diff/bytes_data.bin'\n"
     ]
    }
   ],
   "source": [
    "save_spacy_model(nlp, \"that_one_model_which_is_diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d8fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy_model(model_path, base_model = \"en_core_web_sm\"):\n",
    "\n",
    "    nlp = spacy.load(base_model)\n",
    "    file = open(f'{model_path}/bytes_data.bin',\"rb\")\n",
    "    bytes_data = file.read()\n",
    "    config = nlp.config\n",
    "    lang_cls = spacy.util.get_lang_class(\"en\")\n",
    "    nlp = lang_cls.from_config(config)\n",
    "    nlp = nlp.from_disk(f'{model_path}')\n",
    "    \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d536e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = load_spacy_model(\"ner_sm_do005_ep10_bs128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef730cc5",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb91e8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd262a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_per_epoch(scores, score_metric):\n",
    "    scores_list = []\n",
    "    for item in scores:\n",
    "        epoch_score ={\"epoch\":item[\"iter\"],\n",
    "                     \"train_score\":item[\"train_score\"][f\"ents_{score_metric}\"],\n",
    "                     \"val_score\":item[\"val_score\"][f\"ents_{score_metric}\"]}\n",
    "\n",
    "        scores_list.append(epoch_score)\n",
    "    df_scores = pd.DataFrame(scores_list)\n",
    "    return df_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3388bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_per_entity(scores, score_metric):\n",
    "    # Create a function to transform scores into dataframe\n",
    "    \n",
    "    scores_list = []\n",
    "    for item in scores:\n",
    "        epoch =item[\"iter\"]\n",
    "        \n",
    "        for ent in item[\"val_score\"]['ents_per_type'].keys():\n",
    "            epoch_score ={\n",
    "                \"epoch\":epoch,\n",
    "                \"ent\":ent,\n",
    "                \"train_score\":item[\"train_score\"]['ents_per_type'][ent][score_metric],\n",
    "                \"val_score\":item[\"val_score\"]['ents_per_type'][ent][score_metric]}\n",
    "            scores_list.append(epoch_score)\n",
    "    df_scores = pd.DataFrame(scores_list)\n",
    "    return df_scores       \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = get_metric_per_entity(scores, \"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97417cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for score in [\"train_score\", \"val_score\"]:\n",
    "    \n",
    "    trace=go.Scatter(\n",
    "                x=df_scores.epoch,\n",
    "                y=df_scores[score],\n",
    "                mode='lines',\n",
    "                marker=dict(\n",
    "                size=5\n",
    "                ),\n",
    "            name=score,\n",
    "\n",
    "            )\n",
    "    data.append(trace)\n",
    "    \n",
    "figure=go.Figure(\n",
    "    data=data,\n",
    "    layout=go.Layout(\n",
    "        title=f\"<b>Performance by epoch\",\n",
    "    \n",
    "    ))\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0047ec13",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eaa944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Donald Trump mistook E Jean Carroll, the writer who accuses him of rape, for his ex-wife Marla Maples during a deposition in the case last year, excerpts released in US district court on Wednesday showed.\n",
    "\n",
    "“That’s Marla, yeah,” Trump said, when shown a photograph. “That’s my wife.”\n",
    "\n",
    "The mistake was corrected by a lawyer for the 76-year-old former president. But observers said it could undermine Trump’s claim he could not have attacked Carroll because she is not his “type”.\n",
    "\n",
    "It was not the first release of excerpts from Trump’s deposition, which happened in October. Last week, Trump was shown to have claimed Carroll “said it was very sexy to be raped”.\n",
    "\n",
    "Carroll says Trump raped her in a department store changing room in the mid-1990s. Trump denies it.\n",
    "\n",
    "Carroll sued Trump for defamation and under the Adult Survivors Act, a New York law which allows alleged victims of historical sexual assault to bring cases within a defined timeframe.\n",
    "\n",
    "Trump was married to Maples, the mother of his daughter Tiffany, from 1993 to 1999, between marriages to Ivana Trump, his first wife, and Melania Trump, his third and current spouse.\n",
    "\n",
    "The photograph he thought showed Maples shows Trump in Carroll’s company in the 1990s. In his deposition, Trump said it showed a “receiving line” at an event.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b88ee72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON : Donald Trump\n",
      "PERSON : Jean Carroll\n",
      "PERSON : Marla Maples\n",
      "DATE : last year\n",
      "GPE : US\n",
      "DATE : Wednesday\n",
      "DATE : 76-year-old\n",
      "ORG : Trump\n",
      "PERSON : Carroll\n",
      "ORDINAL : first\n",
      "ORG : Trump\n",
      "DATE : October\n",
      "DATE : Last week\n",
      "ORG : Trump\n",
      "PERSON : Carroll\n",
      "ORG : Trump\n",
      "DATE : the mid-1990s\n",
      "LAW : the Adult Survivors Act\n",
      "GPE : New York\n",
      "NORP : Maples\n",
      "PERSON : Tiffany\n",
      "DATE : 1993\n",
      "DATE : 1999\n",
      "ORG : Ivana Trump\n",
      "ORDINAL : first\n",
      "PERSON : Melania Trump\n",
      "ORDINAL : third\n",
      "PRODUCT : Maples\n",
      "ORG : Trump\n",
      "ORG : Carroll\n",
      "DATE : the 1990s\n",
      "ORG : Trump\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)    \n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.label_} : {ent.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67c98519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PERSON', 'DATE', 'GPE', 'ORG', 'ORDINAL', 'LAW', 'NORP',\n",
       "       'PRODUCT'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f084451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PERSON': '\\x1b[95m\\x1b[1m',\n",
       " 'DATE': '\\x1b[96m\\x1b[1m',\n",
       " 'GPE': '\\x1b[36m\\x1b[1m',\n",
       " 'ORG': '\\x1b[94m\\x1b[1m',\n",
       " 'ORDINAL': '\\x1b[92m\\x1b[1m',\n",
       " 'LAW': '\\x1b[93m\\x1b[1m',\n",
       " 'NORP': '\\x1b[91m\\x1b[1m',\n",
       " 'PRODUCT': '\\x1b[90m\\x1b[1m'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rang = len(obj[1]['entities'])\n",
    "listent = []\n",
    "for i in range(rang):\n",
    "    listent.append(obj[1]['entities'][i][2])\n",
    "\n",
    "listent = pd.unique(listent)\n",
    "\n",
    "len(listent)\n",
    "\n",
    "coldi = {'PURPLE' : '\\033[95m\\033[1m',\n",
    "   'CYAN' : '\\033[96m\\033[1m',\n",
    "   'DARKCYAN' : '\\033[36m\\033[1m',\n",
    "   'BLUE' : '\\033[94m\\033[1m',\n",
    "   'GREEN' : '\\033[92m\\033[1m',\n",
    "   'YELLOW' : '\\033[93m\\033[1m',\n",
    "   'RED' : '\\033[91m\\033[1m',\n",
    "   'GRAY' : '\\033[90m\\033[1m',\n",
    "}\n",
    "colors = list(coldi.values())\n",
    "\n",
    "\n",
    "colmap = dict(zip(listent, colors))\n",
    "colmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d029c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap = {'PERSON': '\\x1b[95m\\x1b[1m',\n",
    " 'DATE': '\\x1b[96m\\x1b[1m',\n",
    " 'GPE': '\\x1b[36m\\x1b[1m',\n",
    " 'ORG': '\\x1b[94m\\x1b[1m',\n",
    " 'ORDINAL': '\\x1b[92m\\x1b[1m',\n",
    " 'LAW': '\\x1b[93m\\x1b[1m',\n",
    " 'NORP': '\\x1b[91m\\x1b[1m',\n",
    " 'PRODUCT': '\\x1b[90m\\x1b[1m'}\n",
    "\n",
    "def highlight_entities(text, ents):\n",
    "    #blue_bold_char = '\\033[94m\\033[1m'\n",
    "    back_to_normal = '\\033[0m'\n",
    "\n",
    "    previous_end=0\n",
    "    text_h =\"\"\n",
    "    for ent in ents[\"entities\"]:\n",
    "\n",
    "        start=ent[0]\n",
    "        end=ent[1]\n",
    "        ent_val = text[start:end]\n",
    "        text_h = text_h + text[previous_end:start]+colmap[ent[2]] +ent_val+back_to_normal \n",
    "        previous_end = end\n",
    "    text_h = text_h+text[previous_end:]\n",
    "    print(text_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d58ac46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_entities(text, nlp):\n",
    "    doc = nlp(text)   \n",
    "    ents = doc.ents\n",
    "    entites = []\n",
    "    for ent in ents:\n",
    "        entites.append((ent.start_char, ent.end_char, ent.label_))\n",
    "        \n",
    "    output = (text, {\"entities\":entites})\n",
    "    highlight_entities(output[0], output[1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c58dd9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1mDonald Trump\u001b[0m mistook E \u001b[95m\u001b[1mJean Carroll\u001b[0m, the writer who accuses him of rape, for his ex-wife \u001b[95m\u001b[1mMarla Maples\u001b[0m during a deposition in the case \u001b[96m\u001b[1mlast year\u001b[0m, excerpts released in \u001b[36m\u001b[1mUS\u001b[0m district court on \u001b[96m\u001b[1mWednesday\u001b[0m showed.\n",
      "\n",
      "“That’s Marla, yeah,” Trump said, when shown a photograph. “That’s my wife.”\n",
      "\n",
      "The mistake was corrected by a lawyer for the \u001b[96m\u001b[1m76-year-old\u001b[0m former president. But observers said it could undermine \u001b[94m\u001b[1mTrump\u001b[0m’s claim he could not have attacked \u001b[95m\u001b[1mCarroll\u001b[0m because she is not his “type”.\n",
      "\n",
      "It was not the \u001b[92m\u001b[1mfirst\u001b[0m release of excerpts from \u001b[94m\u001b[1mTrump\u001b[0m’s deposition, which happened in \u001b[96m\u001b[1mOctober\u001b[0m. \u001b[96m\u001b[1mLast week\u001b[0m, \u001b[94m\u001b[1mTrump\u001b[0m was shown to have claimed \u001b[95m\u001b[1mCarroll\u001b[0m “said it was very sexy to be raped”.\n",
      "\n",
      "Carroll says \u001b[94m\u001b[1mTrump\u001b[0m raped her in a department store changing room in \u001b[96m\u001b[1mthe mid-1990s\u001b[0m. Trump denies it.\n",
      "\n",
      "Carroll sued Trump for defamation and under \u001b[93m\u001b[1mthe Adult Survivors Act\u001b[0m, a \u001b[36m\u001b[1mNew York\u001b[0m law which allows alleged victims of historical sexual assault to bring cases within a defined timeframe.\n",
      "\n",
      "Trump was married to \u001b[91m\u001b[1mMaples\u001b[0m, the mother of his daughter \u001b[95m\u001b[1mTiffany\u001b[0m, from \u001b[96m\u001b[1m1993\u001b[0m to \u001b[96m\u001b[1m1999\u001b[0m, between marriages to \u001b[94m\u001b[1mIvana Trump\u001b[0m, his \u001b[92m\u001b[1mfirst\u001b[0m wife, and \u001b[95m\u001b[1mMelania Trump\u001b[0m, his \u001b[92m\u001b[1mthird\u001b[0m and current spouse.\n",
      "\n",
      "The photograph he thought showed \u001b[90m\u001b[1mMaples\u001b[0m shows \u001b[94m\u001b[1mTrump\u001b[0m in \u001b[94m\u001b[1mCarroll\u001b[0m’s company in \u001b[96m\u001b[1mthe 1990s\u001b[0m. In his deposition, \u001b[94m\u001b[1mTrump\u001b[0m said it showed a “receiving line” at an event.\n"
     ]
    }
   ],
   "source": [
    "obj = text_to_entities(text, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spacy_model(nlp, model_path):\n",
    "    nlp.to_disk(f'{model_path}')\n",
    "    print(f\"Saved model to {model_path}\")\n",
    "    bytes_data = nlp.to_bytes()\n",
    "\n",
    "    f = open(f'{model_path}/bytes_data.bin', 'wb')\n",
    "    f.write(bytes_data)\n",
    "    f.close()\n",
    "    print(f\"Saved bytes_data to f'{model_path}/bytes_data.bin'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_spacy_model(nlp, \"ner_per_and_org_3_do_05_e_10_bs_32_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab56c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5f489c0c09ff820f8ee5076ec4759de7add446fa379c2c24790f576095cb7fd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
